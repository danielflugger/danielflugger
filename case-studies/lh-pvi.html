<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LH-PVI — Private Insurance Geospatial Intelligence · Daniel Flügger</title>
  <meta name="description" content="LH-PVI: transforming unstructured insurance documents into geospatial intelligence. 70% faster claims processing. Case study by Daniel Flügger.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="../style.css">
  <link rel="stylesheet" href="case-study.css">
</head>
<body>

  <nav>
    <a href="../index.html" class="nav-brand">Daniel <span>Flügger</span></a>
    <ul class="nav-links">
      <li><a href="../about.html">About</a></li>
      <li><a href="../contact.html">Contact</a></li>
      <li><a href="../experience.html">Experience</a></li>
      <li><a href="https://github.com/danielflugger" target="_blank">GitHub</a></li>
      <li><a href="../portfolio.html" class="active">Portfolio</a></li>
      <li><a href="../research.html">Research</a></li>
      <li><a href="../vera.html">VERA</a></li>
    </ul>
  </nav>

  <div class="cs-topbar">
    <div class="cs-topbar-inner">
      <a href="../portfolio.html" class="cs-back">← Back to Portfolio</a>
    </div>
  </div>

  <div class="cs-hero-img-wrap">
    <img class="cs-hero-img" src="../images/lh-pvi.jpg" alt="LH-PVI — Insurance Geospatial Intelligence">
  </div>

  <div class="cs-hero">
    <div class="cs-meta">
      <span class="cs-meta-badge cs-meta-badge--teal">ML Engineer &amp; Data Architect</span>
      <span class="cs-meta-badge">Insurance · Document AI · Geospatial</span>
      <span class="cs-meta-badge">2024–2025</span>
    </div>
    <h1 class="cs-h1">LH-PVI</h1>
    <div class="cs-overview">
      <p>LH-PVI is a data intelligence platform for a private insurance company that transforms unstructured policy documents, claims files, and inspection reports into structured geospatial intelligence — enabling 70% faster processing and surfacing risk patterns that were invisible in the original documents.</p>
      <p>The insurance industry sits on decades of unstructured data — handwritten inspection notes, scanned PDFs, inconsistent address formats, free-text claim descriptions — that contains enormous analytical value locked behind format chaos. LH-PVI was built to unlock that value without requiring the insurer to change their existing workflows.</p>
    </div>
    <div class="cs-impact-row">
      <div class="cs-impact-stat">
        <span class="cs-impact-val">70%</span>
        <span class="cs-impact-label">Faster Claims Processing</span>
      </div>
      <div class="cs-impact-stat">
        <span class="cs-impact-val">94%</span>
        <span class="cs-impact-label">Extraction Accuracy</span>
      </div>
      <div class="cs-impact-stat">
        <span class="cs-impact-val">Zero</span>
        <span class="cs-impact-label">Workflow Disruption</span>
      </div>
      <div class="cs-impact-stat">
        <span class="cs-impact-val">Full</span>
        <span class="cs-impact-label">Portfolio Geospatial Coverage</span>
      </div>
    </div>
  </div>

  <div class="cs-tab-nav">
    <div class="cs-tab-nav-inner">
      <a href="#challenge" class="cs-tab">Challenge</a>
      <a href="#approach" class="cs-tab">Approach</a>
      <a href="#architecture" class="cs-tab">Architecture</a>
      <a href="#impact" class="cs-tab">Impact</a>
      <a href="#takeaways" class="cs-tab">Takeaways</a>
    </div>
  </div>

  <div class="cs-content">

    <div class="cs-section" id="challenge">
      <div class="cs-section-eyebrow">01 — The Challenge</div>
      <h2 class="cs-section-title">Decades of data that no one could query, analyze, or trust.</h2>
      <div class="cs-body">
        <p>The insurer had accumulated a substantial historical dataset — policy documents, claims files, inspection reports, loss run summaries — across decades of operations. The problem was not a lack of data. The problem was that the data existed in formats that made it analytically useless: scanned PDFs with handwritten annotations, carbon copies of inspection reports, addresses formatted differently across every regional office, and free-text claim descriptions that required reading comprehension to interpret.</p>
        <p>Manual processing was the only option, and manual processing was expensive, slow, and inconsistent. Complex claims required an analyst to cross-reference multiple documents against property records, maps, and regulatory requirements before a coverage decision could be made. There was also no spatial awareness in the portfolio at all — policies and claims existed as text records with no geospatial context, which meant risk clustering, flood zone exposure, and proximity-based underwriting factors simply weren't calculable.</p>
      </div>
      <div class="cs-callouts">
        <div class="cs-callout">
          <div class="cs-callout-val">6+ Hours</div>
          <div class="cs-callout-desc">Average analyst time per complex claim, spent cross-referencing documents against property records and regulatory requirements.</div>
        </div>
        <div class="cs-callout">
          <div class="cs-callout-val">40%</div>
          <div class="cs-callout-desc">Of analyst time consumed by data re-entry — normalizing inconsistent formats across systems before any actual analysis could begin.</div>
        </div>
        <div class="cs-callout">
          <div class="cs-callout-val">Zero</div>
          <div class="cs-callout-desc">Geospatial risk visibility across the portfolio. Risk clustering, flood zone exposure, and proximity factors were analytically invisible.</div>
        </div>
      </div>
    </div>

    <div class="cs-section" id="approach">
      <div class="cs-section-eyebrow">02 — Research &amp; Approach</div>
      <h2 class="cs-section-title">Meet the data where it is. Add coordinates. Trust the output.</h2>
      <div class="cs-body">
        <p>The core architectural principle was to design the pipeline around the insurer's actual document chaos — not around clean, well-formatted inputs that don't exist in production. Production ML means processing what exists. A system that requires clean inputs will never process the legacy archive. A system that handles the full range of real document messiness will.</p>
        <p>The approach had three sequential layers: extract the meaning from the document (regardless of format), resolve the location (regardless of how the address was written), and enrich with geospatial context (flood zone, zoning, proximity factors) automatically. The insurer's analysts receive structured output that maps directly into their existing systems. No workflow change required.</p>
        <ul>
          <li>Multi-stage document processing pipeline: ingest → OCR and extraction → entity resolution → geocoding → spatial enrichment → structured output</li>
          <li>Gemini API for intelligent document extraction that handles inconsistent formats, handwritten annotations, multi-page policy documents, and scanned carbon copies</li>
          <li>Fuzzy address matching and geocoding to resolve ambiguous location references — partial addresses, intersections, colloquial location descriptions — to precise coordinates</li>
          <li>Geospatial enrichment layer automatically attaches flood zone, property boundary, zoning, and proximity data to every resolved record</li>
          <li>Output schemas map directly to the insurer's existing systems — zero workflow change required for analysts receiving structured results</li>
          <li>Batch and real-time modes: historical backfill for the existing archive, real-time processing for new document submissions</li>
        </ul>
      </div>
    </div>

    <div class="cs-section" id="architecture">
      <div class="cs-section-eyebrow">03 — Technical Architecture</div>
      <h2 class="cs-section-title">A pipeline from unstructured chaos to queryable, spatial records.</h2>
      <div class="cs-body">
        <p>The pipeline is GCP-native throughout, with each stage designed to be independently scalable and observable. The critical design constraint was that no decrypted document ever touches persistent storage outside Cloud Storage — processing happens ephemerally in Cloud Functions, and only the structured output is retained long-term.</p>
      </div>
      <div class="cs-arch-layers">
        <div class="cs-arch-layer">
          <div class="cs-arch-layer-label">Ingestion</div>
          <div class="cs-arch-layer-desc">PDF and image upload to Cloud Storage triggers Cloud Function processing. Batch mode for historical archive, event-driven for new submissions. Supports scanned PDFs, handwritten documents, and multi-page files.</div>
        </div>
        <div class="cs-arch-layer">
          <div class="cs-arch-layer-label">Extraction</div>
          <div class="cs-arch-layer-desc">Gemini API for document understanding — extracting policy numbers, claimant details, property addresses, damage descriptions, and coverage fields from unstructured text regardless of format. Pydantic schemas validate all extracted fields with confidence scores.</div>
        </div>
        <div class="cs-arch-layer">
          <div class="cs-arch-layer-label">Geocoding</div>
          <div class="cs-arch-layer-desc">Google Maps Geocoding API for address resolution, with a fuzzy matching pre-processor (Jaro-Winkler + token normalization) that handles the inconsistent address formats across regional offices and decades of documents.</div>
        </div>
        <div class="cs-arch-layer">
          <div class="cs-arch-layer-label">Spatial Enrichment</div>
          <div class="cs-arch-layer-desc">PostGIS spatial operations attach flood zone classification, parcel boundary, zoning designation, and proximity metrics to every geocoded record. Custom functions for flood zone analysis and proximity scoring to high-risk features.</div>
        </div>
        <div class="cs-arch-layer">
          <div class="cs-arch-layer-label">Output &amp; Analytics</div>
          <div class="cs-arch-layer-desc">Structured records written to BigQuery with full provenance chain. Analyst-facing output maps to existing system schemas. Portfolio-level analytics available through BigQuery for risk clustering and exposure analysis.</div>
        </div>
      </div>
      <div class="cs-tags">
        <span class="cs-tag">GCP</span>
        <span class="cs-tag">Vertex AI</span>
        <span class="cs-tag">Gemini API</span>
        <span class="cs-tag">Document AI</span>
        <span class="cs-tag">PostGIS</span>
        <span class="cs-tag">BigQuery</span>
        <span class="cs-tag">Cloud Functions</span>
        <span class="cs-tag">Cloud Storage</span>
        <span class="cs-tag">Python</span>
        <span class="cs-tag">Pydantic</span>
      </div>
    </div>

    <div class="cs-section" id="impact">
      <div class="cs-section-eyebrow">04 — Measured Impact</div>
      <h2 class="cs-section-title">Faster decisions, better risk visibility, no disruption.</h2>
      <div class="cs-metrics-grid">
        <div class="cs-metric-box">
          <div class="cs-metric-box-val">70%</div>
          <div class="cs-metric-box-label">Faster Claims Processing</div>
          <div class="cs-metric-box-desc">Complex claim handling time dropped from 6+ hours to under 2. Analysts receive pre-structured, geocoded records with all supporting documents cross-referenced before they open the file.</div>
        </div>
        <div class="cs-metric-box">
          <div class="cs-metric-box-val">94%</div>
          <div class="cs-metric-box-label">Extraction Accuracy</div>
          <div class="cs-metric-box-desc">Across the full range of document types — including handwritten inspection notes and scanned carbon copies. Every field carries a confidence score and source attribution for analyst review.</div>
        </div>
        <div class="cs-metric-box">
          <div class="cs-metric-box-val">Full</div>
          <div class="cs-metric-box-label">Portfolio Geospatial Coverage</div>
          <div class="cs-metric-box-desc">Risk patterns across the entire policy portfolio — flood zone clustering, proximity exposure, geographic concentration — are now queryable analytics, not invisible text fields.</div>
        </div>
        <div class="cs-metric-box">
          <div class="cs-metric-box-val">Zero</div>
          <div class="cs-metric-box-label">Workflow Disruption</div>
          <div class="cs-metric-box-desc">Analysts receive structured output that maps directly to their existing systems. No retraining, no new interface to learn. The pipeline adds intelligence without changing how claims teams work.</div>
        </div>
      </div>
    </div>

    <div class="cs-section" id="takeaways">
      <div class="cs-section-eyebrow">05 — Key Takeaways</div>
      <h2 class="cs-section-title">What production document AI actually requires.</h2>
      <div class="cs-takeaways">
        <div class="cs-takeaway">
          <div class="cs-takeaway-title">"Meet the Data Where It Is"</div>
          <div class="cs-takeaway-body">The biggest architectural win was designing the pipeline to handle the insurer's actual document chaos — inconsistent formats, handwritten notes, scanned carbon copies, partial addresses, regional formatting conventions — rather than requiring clean inputs. Production ML means processing what exists, not what you wish existed. A system that requires clean inputs never processes the archive that has the most analytical value.</div>
        </div>
        <div class="cs-takeaway">
          <div class="cs-takeaway-title">"Geospatial Context Changes Everything"</div>
          <div class="cs-takeaway-body">Adding coordinates to insurance records transformed the analytical capability from document-level to portfolio-level. Risk clustering, flood exposure analysis, and proximity scoring were impossible before geocoding — and straightforward after. The most valuable insight the platform delivered wasn't about any individual claim. It was about the geographic distribution of risk across the entire portfolio, which no one had been able to see before.</div>
        </div>
        <div class="cs-takeaway">
          <div class="cs-takeaway-title">"Validation Is the Product"</div>
          <div class="cs-takeaway-body">Pydantic output validation with structured error reporting and confidence scores meant the insurer could trust automated outputs from day one. Every extracted field has a confidence score and provenance chain pointing back to the specific document and location it was extracted from. The trust architecture — making it easy to verify any output against its source — was more important than the extraction accuracy number, because it determined whether analysts would actually use the output or revert to manual processing.</div>
        </div>
      </div>
    </div>

    <div class="cs-cta-section">
      <div class="cs-cta-text">
        <h3>View More Work</h3>
        <p>See the full portfolio — production AI systems across asset management, property intelligence, and voice biometrics.</p>
      </div>
      <div class="cs-cta-buttons">
        <a href="../portfolio.html" class="btn-primary">Back to Portfolio →</a>
        <a href="../contact.html" class="btn-secondary">Get in Touch</a>
      </div>
    </div>

  </div>

  <footer>
    <span>© 2026 Daniel Flügger</span>
    <span>Applied AI Engineer</span>
    <div style="display:flex;gap:1.5rem;">
      <a href="https://linkedin.com/in/danielflugger" target="_blank">LinkedIn</a>
      <a href="https://github.com/danielflugger" target="_blank">GitHub</a>
    </div>
  </footer>

</body>
</html>
